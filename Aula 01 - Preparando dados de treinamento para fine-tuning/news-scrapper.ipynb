{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMijuVjl1_2X",
        "outputId": "50dffe7f-1ad5-4c52-9c07-1b1b8a82b9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Conexão com o Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qpUkpvTw2FsX"
      },
      "outputs": [],
      "source": [
        "#Importar bibliotecas\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OIOgTXQ-2F47"
      },
      "outputs": [],
      "source": [
        "#Definindo a função que retornará os links\n",
        "\n",
        "def scrape_cnn_links(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Se a request tiver retorno com sucesso\n",
        "    if response.status_code == 200:\n",
        "        # Parsing do conteúdo da página\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        valid_links = []\n",
        "\n",
        "        # Encontrar os links de notícias\n",
        "        for a in soup.find_all('a', href=True):\n",
        "            href = a['href']\n",
        "            # Checagem se o link encontrado é um documento HTML\n",
        "            if href.startswith('/'):# and href.endswith('.html'):\n",
        "                # Concatenar com a URL padrão do site\n",
        "                full_link = f\"https://www.cnn.com{href}\"\n",
        "                valid_links.append(full_link)\n",
        "            else: pass\n",
        "\n",
        "        return valid_links\n",
        "    else:\n",
        "        return f\"Falha ao extrair o conteúdo da notícia: {response.status_code}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9VRX_63j2F7u"
      },
      "outputs": [],
      "source": [
        "# Definindo a URL padrão\n",
        "url = \"https://edition.cnn.com/world\"\n",
        "\n",
        "# Chama a função de scrap dos dados e salva as URLs em um arquivo\n",
        "links = scrape_cnn_links(url)\n",
        "with open('CNN_Links.txt', 'w') as file:\n",
        "    for link in links:\n",
        "        file.write(link + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Eew78btb2F-y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TT1XbZ5z2GCc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}